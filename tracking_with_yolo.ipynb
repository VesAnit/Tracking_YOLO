{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c189272-df2e-413d-ad71-cbb27d454d17",
   "metadata": {},
   "source": [
    "**Stage 1**: Vehicle Detection and Tracking\n",
    "Vehicle detection was implemented using YOLOv8 (Ultralytics), focusing on the \"car\" class from the COCO dataset. Integrated object tracking (e.g., BoT-SORT) was enabled to assign consistent unique IDs to each detected vehicle across frames. Bounding boxes were drawn around vehicles, labeled with their class and ID to support object continuity during tracking.\n",
    "\n",
    "**Stage 2**: Defining the Counting Line\n",
    "A virtual counting line was defined using two coordinate points (x1, y1) and (x2, y2), creating either a horizontal or vertical line on the video frame. This line was rendered on-screen to provide a visual reference for crossing detection.\n",
    "\n",
    "**Stage 3**: Crossing Logic and Counting Mechanism\n",
    "For each tracked object, the center of its bounding box was computed. The system monitored the movement trajectory of this center point to determine whether the object crossed the defined line. To ensure reliable counting:\n",
    "\n",
    "Only one direction of crossing (e.g., left-to-right) was considered valid.\n",
    "\n",
    "Each object was counted only once by tracking its unique ID and marking it as “counted” after crossing.\n",
    "\n",
    "**Stage 4**: Visualization\n",
    "The visualization layer displayed:\n",
    "\n",
    "Bounding boxes with object class and ID labels.\n",
    "\n",
    "The defined counting line.\n",
    "\n",
    "Center points of tracked objects.\n",
    "\n",
    "A dynamic counter showing the total number of crossings, updated in real time.\n",
    "\n",
    "Additionally, objects that successfully crossed the line were visually distinguished (e.g., with a different bounding box color or label) to reflect their counted status.\n",
    "\n",
    "**Stage 5**: Testing and Evaluation\n",
    "The complete system was tested on sample video footage containing moving vehicles. The tracking and counting pipeline operated correctly, identifying and counting vehicles as they crossed the predefined line. Additional features were considered for further development, such as multi-class support, bidirectional counting, and speed estimation.\n",
    "\n",
    "**As an additional feature**, a designated lane area was defined using a bounding box over a specific region of the frame (e.g., a traffic lane). The system monitored tracked vehicles to determine whether their center points entered this predefined zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a440b7-ee89-44ce-907f-30649cbdb5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962526b-dbbb-4c76-b25a-1c88a586314b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c53b26-b5e3-4a80-a24b-2fb45e0488d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lap in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (0.5.12)\n",
      "Requirement already satisfied: ultralytics in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (8.3.148)\n",
      "Requirement already satisfied: opencv-python in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from lap) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/conda_pkg/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install lap ultralytics opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a9122-647e-4422-808a-54d168c21bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "952e2182-71dd-41d9-bb7c-b7bd4708b703",
   "metadata": {},
   "source": [
    "Let's import everything we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4e7db-fc89-4874-b6a0-c6c6759b0505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b61e66d6-4f41-409b-8a13-0b28f7926aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from shapely.geometry import Point, Polygon\n",
    "import time\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cfb01fa-2e7b-4fec-a7ca-42b7f0466cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "0.20.1\n",
      "Used device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Used device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46e540c5-9268-4515-83c8-f68b16bd38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747298a8-a97d-4fa5-be37-fb699e336805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bac4b7ab-6d03-4144-908c-ff6d07a85632",
   "metadata": {},
   "source": [
    "This section reads a video file and creates a new version with a reduced frame rate (10 FPS) and smaller resolution (half the original size). It calculates the appropriate frame skip interval to match the target FPS and writes only the selected, resized frames to a new output file (video_10fps.mp4). This preprocessing step helps optimize performance for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1daef-e596-4a2f-8ac0-f8d6d1eca725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfe1f80c-66df-46cd-bd48-7e8444dec729",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video/video_cropped.mp4\")\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "target_fps = 10\n",
    "skip = max(1, round(fps / target_fps))\n",
    "size = (w//2, h//2)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('video/video_10fps.mp4', fourcc, target_fps, size)\n",
    "\n",
    "frame_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_id += 1\n",
    "    if frame_id % skip:\n",
    "        continue\n",
    "    small = cv2.resize(frame, size)\n",
    "    out.write(small)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa12ca7-da69-4067-831e-53bcc904e2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd631751-e3d6-48d2-a8af-6df38b15e470",
   "metadata": {},
   "source": [
    "This section applies YOLOv8 object detection and tracking to a preprocessed video (video_10fps.mp4). The model is configured to use the BoT-SORT tracker and filter for the \"car\" class (class ID 2 in the COCO dataset).\n",
    "\n",
    "For each frame:\n",
    "\n",
    "YOLOv8 performs tracking with persistent object IDs.\n",
    "\n",
    "Bounding boxes and labels are rendered directly on the frame.\n",
    "\n",
    "The annotated frame is written to an output file (final_video.mp4) using preprocessed video with low FPS and resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77b7b2-7e28-4583-814f-0659bf9a29a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5912e1b1-e563-41f9-bac8-bbe21027caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")\n",
    "model.to(\"cuda\")\n",
    "model.tracker = \"botsort.yaml\"\n",
    "classes = (2,)  # class \"car\"\n",
    "\n",
    "cap = cv2.VideoCapture(\"video/video_10fps.mp4\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0 / fps\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"video/final_video.mp4\", fourcc, fps, (w, h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd8476-4eb8-477e-8c90-98a299c10027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2ea475-34a4-470c-b78d-4b2e3e2efc80",
   "metadata": {},
   "source": [
    "A horizontal counting line was positioned at the vertical center of the frame to detect vehicle crossings.\n",
    "\n",
    "In addition, a rotated rectangular zone was defined in the lower part of the frame to monitor whether vehicles entered a specific area (e.g., a traffic lane). The zone was rotated by approximately 15 degrees. This setup enabled detection of vehicles entering that marked lane area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597ccf76-5efb-4d6e-af97-ddcd5455ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_start = (0, h // 2)\n",
    "line_end = (w, h // 2)\n",
    "line_y = h // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "332a65ef-5de2-4a68-b5ce-7015f737eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = Polygon([\n",
    "    (-95, 332),\n",
    "    (213, 249),\n",
    "    (223, 287),\n",
    "    (-85, 370)\n",
    "])\n",
    "\n",
    "rect_pts_np = np.array(polygon.exterior.coords[:-1], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2ee6f-799e-4431-b085-c08b8e50d878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d40cb7-f2e8-49a0-8e9d-a665e13bf0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9706aa0-befd-47a3-bd44-e5473db05e95",
   "metadata": {},
   "source": [
    "The four corner points of the rotated rectangular zone were computed by applying rotation transformations around its center. Each corner is calculated using trigonometric functions based on the rectangle's width, height, center coordinates, and rotation angle. The resulting points define the polygon representing the restricted lane area for vehicle entry detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889fba33-fcf3-4346-acda-7de7c88475ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04861b8-8434-4a54-90b6-44ab2ee4113e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526113cd-18a3-45af-8dc6-1b4ebe958c24",
   "metadata": {},
   "source": [
    "Sets and dictionaries were initialized to keep track of previously detected object centers and to ensure that each tracked vehicle is counted only once when crossing the counting line or entering the designated zone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ad1ce-ef56-4a48-aff6-17124abecb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3d259b6-0239-4e6d-bb6a-c4f1a3591717",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_centers = {}\n",
    "counted_ids_line = set()\n",
    "counted_ids_zone = set()\n",
    "line_count = 0\n",
    "zone_count = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fbf6b-6562-435c-aa5e-4855a00c54f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12381600-994f-44a7-885a-ccf75ab2da39",
   "metadata": {},
   "source": [
    "**Vehicle Tracking, Counting, and Visualization Loop**\n",
    "\n",
    "The video is processed frame-by-frame in a loop:\n",
    "\n",
    "For each frame, YOLOv8 with the BoT-SORT tracker detects and tracks cars, outputting bounding boxes, unique IDs, and object coordinates.\n",
    "\n",
    "For each detected vehicle:\n",
    "\n",
    "The center point coordinates are calculated.\n",
    "\n",
    "The vehicle's previous center position is retrieved to track movement direction.\n",
    "\n",
    "Crossing the horizontal counting line is detected by comparing previous and current y-coordinates; each vehicle is counted only once when crossing.\n",
    "\n",
    "Entry into the rotated restricted zone is checked using cv2.pointPolygonTest on the defined polygon; vehicles are counted only once upon entering.\n",
    "\n",
    "Vehicles that have crossed the line or entered the zone are marked with green or red bounding boxes, respectively; others are marked in blue.\n",
    "\n",
    "The counting line and restricted zone polygon are drawn on the frame with corresponding counters displayed.\n",
    "\n",
    "The annotated frame is written to the output video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92408b1-76bb-4114-bb16-ce006bf7d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2a94df8-f92f-4ae6-8120-4a8881033482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 cars, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 16.1ms\n",
      "Speed: 0.7ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.4ms\n",
      "Speed: 2.9ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.1ms\n",
      "Speed: 1.5ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 2.5ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.4ms\n",
      "Speed: 2.9ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.4ms\n",
      "Speed: 2.6ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 3.1ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.1ms\n",
      "Speed: 1.7ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.1ms\n",
      "Speed: 0.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 0.7ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.1ms\n",
      "Speed: 0.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.1ms\n",
      "Speed: 0.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 0.7ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 3.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.1ms\n",
      "Speed: 0.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.1ms\n",
      "Speed: 1.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 1.8ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.1ms\n",
      "Speed: 1.7ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.4ms\n",
      "Speed: 2.8ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.8ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 16.1ms\n",
      "Speed: 0.8ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 0.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 17.8ms\n",
      "Speed: 3.1ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.1ms\n",
      "Speed: 0.7ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 0.9ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.9ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.4ms\n",
      "Speed: 2.8ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 1.9ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.6ms\n",
      "Speed: 3.0ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.1ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 3.2ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 18.4ms\n",
      "Speed: 1.8ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 0.9ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.1ms\n",
      "Speed: 0.7ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 3.1ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 3.4ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.4ms\n",
      "Speed: 2.9ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 2.8ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.1ms\n",
      "Speed: 0.9ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.4ms\n",
      "Speed: 2.6ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.4ms\n",
      "Speed: 2.1ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.1ms\n",
      "Speed: 1.0ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    start = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True, classes=classes, tracker=model.tracker)\n",
    "    frame = results[0].orig_img.copy()\n",
    "    boxes = results[0].boxes\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            if box.id is None:\n",
    "                continue\n",
    "\n",
    "            id = int(box.id.item())\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            prev_center = prev_centers.get(id, (cx, cy))\n",
    "            prev_cy = prev_center[1]\n",
    "\n",
    "            if id not in counted_ids_line and prev_cy > line_y and cy <= line_y:\n",
    "                line_count += 1\n",
    "                counted_ids_line.add(id)\n",
    "\n",
    "            if id not in counted_ids_zone:\n",
    "                point = Point(cx, cy)\n",
    "                if polygon.contains(point):\n",
    "                    zone_count += 1\n",
    "                    counted_ids_zone.add(id)\n",
    "\n",
    "\n",
    "            prev_centers[id] = (cx, cy)\n",
    "\n",
    "            if id in counted_ids_zone:\n",
    "                color = (0, 0, 255)\n",
    "            elif id in counted_ids_line:\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.circle(annotated, (cx, cy), 4, color, -1)\n",
    "            cv2.putText(annotated, f\"ID: {id}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "\n",
    "    cv2.line(annotated, line_start, line_end, (0, 255, 255), 2)\n",
    "    cv2.putText(annotated, f\"Line crossed: {line_count}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.polylines(annotated, [rect_pts_np], isClosed=True, color=(255, 255, 0), thickness=2)\n",
    "    cv2.putText(annotated, f\"Restricted zone crossed: {zone_count}\", (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "    out.write(annotated)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    to_wait = frame_time - elapsed\n",
    "    if to_wait > 0:\n",
    "        time.sleep(to_wait)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15519e7d-528f-4231-b365-e5e1407410fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7140f89b-629f-492f-910d-04fc60feae7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e41c8-8564-4390-9fba-df564f0487b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5499389-4794-4f2c-8ba6-860c6c21ee35",
   "metadata": {},
   "source": [
    "**All five main stages and the additional task have been successfully implemented. Both counting mechanisms—line crossing and zone entry—function correctly without errors. Object detection is stable and reliable, and the visualization of bounding boxes, tracking IDs, counting lines, and zones is clearly presented.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08e1ab-de4d-4416-97a3-538c97bb7bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
